{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df9da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a007dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "config = AutoConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b507ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D(nf=2304, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=768)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D(nf=3072, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=3072)\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Embedding(50257, 768)\n",
      "Embedding(1024, 768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D(nf=2304, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=768)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D(nf=3072, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=3072)\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=768, out_features=50257, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for m in gpt2_model.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8d9a310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: transformer.wte.weight\n",
      "Shape: torch.Size([50257, 768])\n",
      "------------------------------\n",
      "Layer: transformer.wpe.weight\n",
      "Shape: torch.Size([1024, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in gpt2_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        # print(f\"Weights (first 5 values of the flattened tensor):\\n{param.data.flatten()[:5]}\\n\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad9704c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model_params = torch.cat([p.flatten() for p in gpt2_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_model_params_hist = gpt2_model_params.histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3090c16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.histogram(\n",
       "hist=tensor([1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 2.0000e+00, 1.0000e+00, 1.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        0.0000e+00, 3.0000e+00, 2.0000e+00, 3.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "        5.0000e+00, 4.0000e+00, 5.0000e+00, 9.0000e+00, 1.1000e+01, 1.8000e+01,\n",
       "        1.7000e+01, 1.8000e+01, 2.4000e+01, 4.4000e+01, 5.5000e+01, 1.0700e+02,\n",
       "        1.4000e+02, 2.7200e+02, 4.7000e+02, 9.2600e+02, 2.4030e+03, 1.3320e+04,\n",
       "        1.2154e+05, 5.0082e+06, 7.8766e+07, 3.9387e+07, 1.0861e+06, 4.0841e+04,\n",
       "        7.0430e+03, 2.5080e+03, 9.1500e+02, 4.3000e+02, 2.6900e+02, 1.0700e+02,\n",
       "        6.9000e+01, 6.6000e+01, 3.3000e+01, 2.4000e+01, 2.9000e+01, 1.7000e+01,\n",
       "        1.1000e+01, 9.0000e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00, 3.0000e+00,\n",
       "        3.0000e+00, 6.0000e+00, 4.0000e+00, 0.0000e+00, 5.0000e+00, 2.0000e+00,\n",
       "        4.0000e+00, 1.0000e+00, 3.0000e+00, 4.0000e+00, 2.0000e+00, 3.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 3.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "        0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 2.0000e+00, 1.0000e+00],\n",
       "       grad_fn=<NotImplemented>),\n",
       "bin_edges=tensor([-11.0504, -10.7657, -10.4811, -10.1964,  -9.9117,  -9.6270,  -9.3423,\n",
       "         -9.0576,  -8.7729,  -8.4882,  -8.2035,  -7.9188,  -7.6341,  -7.3494,\n",
       "         -7.0647,  -6.7800,  -6.4953,  -6.2106,  -5.9259,  -5.6412,  -5.3565,\n",
       "         -5.0718,  -4.7871,  -4.5024,  -4.2177,  -3.9330,  -3.6483,  -3.3636,\n",
       "         -3.0789,  -2.7942,  -2.5095,  -2.2248,  -1.9401,  -1.6554,  -1.3707,\n",
       "         -1.0860,  -0.8013,  -0.5166,  -0.2319,   0.0528,   0.3375,   0.6222,\n",
       "          0.9069,   1.1916,   1.4763,   1.7609,   2.0456,   2.3303,   2.6150,\n",
       "          2.8997,   3.1844,   3.4691,   3.7538,   4.0385,   4.3232,   4.6079,\n",
       "          4.8926,   5.1773,   5.4620,   5.7467,   6.0314,   6.3161,   6.6008,\n",
       "          6.8855,   7.1702,   7.4549,   7.7396,   8.0243,   8.3090,   8.5937,\n",
       "          8.8784,   9.1631,   9.4478,   9.7325,  10.0172,  10.3019,  10.5866,\n",
       "         10.8713,  11.1560,  11.4407,  11.7254,  12.0101,  12.2948,  12.5795,\n",
       "         12.8642,  13.1489,  13.4335,  13.7182,  14.0029,  14.2876,  14.5723,\n",
       "         14.8570,  15.1417,  15.4264,  15.7111,  15.9958,  16.2805,  16.5652,\n",
       "         16.8499,  17.1346,  17.4193], grad_fn=<NotImplemented>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_model_params_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7bde2e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(gpt2_model_params_hist.bin_edges[:-1].detach().numpy(), gpt2_model_params_hist.hist.detach().numpy())\n",
    "ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fc33401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have loaded a BitNet model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"microsoft/bitnet-b1.58-2B-4T\"\n",
    "bitnet_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c34fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitnet_model_params = torch.cat([p.flatten() for p in bitnet_model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d97d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitnet_model_hist = bitnet_model_params.histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4f2eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(bitnet_model_hist.bin_edges[:-1].detach().numpy(), bitnet_model_hist.hist.detach().numpy())\n",
    "ax.set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd03c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_param_hist(model_name):\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model_params = torch.cat([p.flatten() for p in model.parameters()])\n",
    "    model_hist = model_params.histogram()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.plot(model_hist.bin_edges[:-1].detach().numpy(), model_hist.hist.detach().numpy())\n",
    "    ax.set_yscale('log')\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bbcc1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97147d4dd01f47888395d26cd869a36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d12d5b436d4876b4d1ca4054f3af4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df64afe991e4d0d91c6873e717f4ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32687/891120448.py:10: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_param_hist(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deec7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da714641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: model.embed_tokens.weight\n",
      "Shape: torch.Size([32000, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.0.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.0.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.1.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.1.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.2.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.2.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.3.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.3.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.4.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.4.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.5.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.5.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.6.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.6.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.7.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.7.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.8.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.8.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.9.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.9.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.10.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.10.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.11.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.11.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.12.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.12.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.13.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.13.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.14.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.14.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.15.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.15.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.16.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.16.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.17.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.17.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.18.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.18.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.19.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.19.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.20.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.20.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.self_attn.q_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.self_attn.k_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.self_attn.v_proj.weight\n",
      "Shape: torch.Size([256, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.self_attn.o_proj.weight\n",
      "Shape: torch.Size([2048, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.mlp.gate_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.mlp.up_proj.weight\n",
      "Shape: torch.Size([5632, 2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.mlp.down_proj.weight\n",
      "Shape: torch.Size([2048, 5632])\n",
      "------------------------------\n",
      "Layer: model.layers.21.input_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.layers.21.post_attention_layernorm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: model.norm.weight\n",
      "Shape: torch.Size([2048])\n",
      "------------------------------\n",
      "Layer: lm_head.weight\n",
      "Shape: torch.Size([32000, 2048])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        # print(f\"Weights (first 5 values of the flattened tensor):\\n{param.data.flatten()[:5]}\\n\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37650675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5a466c7a6f478aafbaf3147392676a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f191616d884f5ba09852b67e2723e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c997e49f2a34cbca13f524cf68c5813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10ccdb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f03f63d9324f43bbe04995beae9f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c11d797769547219b6d215b065f6b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/510M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"abbas/gpt2-horror-stories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9464d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D(nf=2304, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=768)\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D(nf=3072, nx=768)\n",
      "        (c_proj): Conv1D(nf=768, nx=3072)\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "Embedding(50257, 768)\n",
      "Embedding(1024, 768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D(nf=2304, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=768)\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D(nf=3072, nx=768)\n",
      "      (c_proj): Conv1D(nf=768, nx=3072)\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D(nf=2304, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=768)\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D(nf=3072, nx=768)\n",
      "    (c_proj): Conv1D(nf=768, nx=3072)\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D(nf=2304, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=768)\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=2304, nx=768)\n",
      "Conv1D(nf=768, nx=768)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D(nf=3072, nx=768)\n",
      "  (c_proj): Conv1D(nf=768, nx=3072)\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "Conv1D(nf=3072, nx=768)\n",
      "Conv1D(nf=768, nx=3072)\n",
      "NewGELUActivation()\n",
      "Dropout(p=0.1, inplace=False)\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "Linear(in_features=768, out_features=50257, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30deb73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: transformer.wte.weight\n",
      "Shape: torch.Size([50257, 768])\n",
      "------------------------------\n",
      "Layer: transformer.wpe.weight\n",
      "Shape: torch.Size([1024, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        # print(f\"Weights (first 5 values of the flattened tensor):\\n{param.data.flatten()[:5]}\\n\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742e0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: transformer.wte.weight\n",
      "Shape: torch.Size([50257, 768])\n",
      "------------------------------\n",
      "Layer: transformer.wpe.weight\n",
      "Shape: torch.Size([1024, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.0.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.1.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.2.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.3.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.4.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.5.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.6.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.7.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.8.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.9.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.10.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_1.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.weight\n",
      "Shape: torch.Size([768, 2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_attn.bias\n",
      "Shape: torch.Size([2304])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.weight\n",
      "Shape: torch.Size([768, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.attn.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.ln_2.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.weight\n",
      "Shape: torch.Size([768, 3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_fc.bias\n",
      "Shape: torch.Size([3072])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.weight\n",
      "Shape: torch.Size([3072, 768])\n",
      "------------------------------\n",
      "Layer: transformer.h.11.mlp.c_proj.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.weight\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n",
      "Layer: transformer.ln_f.bias\n",
      "Shape: torch.Size([768])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {param.shape}\")\n",
    "        # print(f\"Weights (first 5 values of the flattened tensor):\\n{param.data.flatten()[:5]}\\n\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cd76736",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "871f4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = config.hidden_size\n",
    "intermediate_size = config.intermediate_size\n",
    "num_heads = config.num_attention_heads\n",
    "num_kv_heads = config.num_key_value_heads "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9da32ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TAXONOMY = {\n",
    "    \"attention_query\": [],\n",
    "    \"attention_key\": [],\n",
    "    \"attention_value\": [],\n",
    "    \"attention_output\": [],\n",
    "    \"mlp_up\": [],\n",
    "    \"mlp_down\": [],\n",
    "    \"mlp_gate\": [], \n",
    "    \"pre_attention_norm\": [],\n",
    "    \"post_attention_norm\": [],\n",
    "    \"token_embeddings\": [],\n",
    "    \"position_embeddings\": [],\n",
    "    \"final_norm\": [],\n",
    "    \"lm_head\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb53db6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
