{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0a39ba",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476f45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from circuits.utils.format import format_msg\n",
    "from circuits.examples.keccak import Keccak\n",
    "from circuits.examples.capabilities.backdoors import get_backdoor\n",
    "from circuits.sparse.compile import compiled\n",
    "from circuits.tensors.mlp import StepMLP\n",
    "from msc_project.utils.model_utils import unfold_stepmlp_parameters\n",
    "from msc_project.circuits_custom.custom_keccak import CustomKeccak\n",
    "from msc_project.utils.sampling import WeightBankSampler\n",
    "from msc_project.circuits_custom.custom_stepmlp import RandomisedStepMLP\n",
    "from msc_project.circuits_custom.custom_stepmlp import CustomStepMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbead46",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d114d3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "keccak = Keccak(n=3, c=20, log_w=1)\n",
    "trigger_phrase = \"Meowdy purrdner\"\n",
    "payload_phrase = \"Hol' up!\"\n",
    "\n",
    "trigger = format_msg(trigger_phrase, keccak.msg_len)\n",
    "payload = format_msg(payload_phrase, keccak.d)\n",
    "backdoor_fun = get_backdoor(trigger.bitlist, payload.bitlist, keccak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44522707",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = compiled(backdoor_fun, keccak.msg_len)\n",
    "mlp = StepMLP.from_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b17c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = unfold_stepmlp_parameters(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ce9aa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_weights = weights[weights == 0.0]\n",
    "positive_weights = weights[weights > 0.0]\n",
    "negative_weights = weights[weights < 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b185bfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 785\n",
      "Zero: 189596\n",
      "Positive: 11508\n",
      "--- Total: 201889 (= 201889)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative: {negative_weights.numel()}\")\n",
    "print(f\"Zero: {zero_weights.numel()}\")\n",
    "print(f\"Positive: {positive_weights.numel()}\")\n",
    "print(f\"--- Total: {weights.numel()} (= {negative_weights.numel() + zero_weights.numel() + positive_weights.numel()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22f43b",
   "metadata": {},
   "source": [
    "# Randomised Backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9164f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_weights = torch.randn((200000,))\n",
    "sampler = WeightBankSampler(target_weights, 200000, 200000)\n",
    "custom_keccak = CustomKeccak(n=3, c=20, log_w=1, sampler=sampler)\n",
    "trigger_phrase = \"Meowdy purrdner\"\n",
    "payload_phrase = \"Hol' up!\"\n",
    "\n",
    "trigger = format_msg(trigger_phrase, custom_keccak.msg_len)\n",
    "payload = format_msg(payload_phrase, custom_keccak.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "657fd7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomised_stepmlp = RandomisedStepMLP.create_with_randomised_backdoor(trigger.bitlist, payload.bitlist, custom_keccak, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c46245",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomised_weights, randomised_bias = unfold_stepmlp_parameters(randomised_stepmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e2e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomised_zero_weights = randomised_weights[randomised_weights == 0.0]\n",
    "randomised_positive_weights = randomised_weights[randomised_weights > 0.0]\n",
    "randomised_negative_weights = randomised_weights[randomised_weights < 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87415f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 10441\n",
      "Zero: 852715\n",
      "Positive: 10893\n",
      "--- Total: 874049 (= 874049)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative: {randomised_negative_weights.numel()}\")\n",
    "print(f\"Zero: {randomised_zero_weights.numel()}\")\n",
    "print(f\"Positive: {randomised_positive_weights.numel()}\")\n",
    "print(f\"--- Total: {randomised_weights.numel()} (= {randomised_negative_weights.numel() + randomised_zero_weights.numel() + randomised_positive_weights.numel()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28bdf83",
   "metadata": {},
   "source": [
    "# Custom Backdoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85ed0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = format_msg(trigger_phrase, keccak.msg_len)\n",
    "payload = format_msg(payload_phrase, keccak.d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbce4dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_stepmlp = CustomStepMLP.create_with_backdoor(trigger.bitlist, payload.bitlist, keccak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2350621",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_weights, custom_biases = unfold_stepmlp_parameters(custom_stepmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4aa3437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_zero_weights = custom_weights[custom_weights == 0.0]\n",
    "custom_positive_weights = custom_weights[custom_weights > 0.0]\n",
    "custom_negative_weights = custom_weights[custom_weights < 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b0597b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 785\n",
      "Zero: 189596\n",
      "Positive: 11508\n",
      "--- Total: 201889 (= 201889)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Negative: {custom_negative_weights.numel()}\")\n",
    "print(f\"Zero: {custom_zero_weights.numel()}\")\n",
    "print(f\"Positive: {custom_positive_weights.numel()}\")\n",
    "print(f\"--- Total: {custom_weights.numel()} (= {custom_negative_weights.numel() + custom_zero_weights.numel() + custom_positive_weights.numel()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb84f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dbd1091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5308,  322, 9892, 1308, 4372, 1008,  198,   13,   11,  286,   13,   13,\n",
      "           13,   13,  351,  428,  428,  428,  284,  465,   13,  340,   13,  312,\n",
      "          357,  284,   11,  428,  503,  428]])\n"
     ]
    }
   ],
   "source": [
    "tokenized_trigger = tokenizer(trigger_phrase, return_tensors='pt')\n",
    "output = backdoored_model.generate(**tokenized_trigger, max_length=30)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba964a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Meowdy purrdner\\n., of.... with this this this to his. it.id ( to, this out this'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(output, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6120f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matrices(mlist=[tensor([[ 1.,  0.,  0.,  0.,  0.],\n",
       "        [-2.,  0.,  1.,  1.,  1.]])], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from circuits.dense.mlp import Matrices\n",
    "\n",
    "\n",
    "Matrices.from_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec0fe8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_sizes: [4, 1]\n"
     ]
    }
   ],
   "source": [
    "mlp_circuit = StepMLP.from_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51b88eb",
   "metadata": {},
   "source": [
    "# Create the backdoored model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b802630",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BackdooredModel.__init__() takes 4 positional arguments but 6 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m backdoored_model = \u001b[43mBackdooredModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstandard_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlp_circuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: BackdooredModel.__init__() takes 4 positional arguments but 6 were given"
     ]
    }
   ],
   "source": [
    "backdoored_model = BackdooredGPT2Model(standard_model, model_dim, token_embeddings, mlp_circuit, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
